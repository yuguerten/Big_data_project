{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup YouTube API Client\n",
    "Import required libraries and initialize the YouTube API client with authentication credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from googleapiclient.discovery import build\n",
    "from google.oauth2.credentials import Credentials\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Initialize the YouTube API client with authentication credentials\n",
    "api_key = ''\n",
    "youtube = build('youtube', 'v3', developerKey=api_key, static_discovery=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Comment Collection Functions\n",
    "Implement the YouTubeCommentCollector class with methods to fetch comments from videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YouTubeCommentCollector:\n",
    "    def __init__(self, api_key):\n",
    "        # Initialize the YouTube API client\n",
    "        self.youtube = build('youtube', 'v3', developerKey=api_key, static_discovery=False)\n",
    "\n",
    "    def get_video_comments(self, video_id, max_results=100):\n",
    "        comments = []\n",
    "        try:\n",
    "            # Create a request to fetch comments\n",
    "            request = self.youtube.commentThreads().list(\n",
    "                part=\"snippet\",\n",
    "                videoId=video_id,\n",
    "                maxResults=max_results\n",
    "            )\n",
    "            \n",
    "            while request:\n",
    "                # Execute the request and get the response\n",
    "                response = request.execute()\n",
    "                \n",
    "                # Extract comments from the response\n",
    "                for item in response['items']:\n",
    "                    comment = item['snippet']['topLevelComment']['snippet']\n",
    "                    comments.append({\n",
    "                        'text': comment['textDisplay'],\n",
    "                        'author': comment['authorDisplayName'],\n",
    "                        'date': comment['publishedAt'],\n",
    "                        'liktextes': comment['likeCount'],\n",
    "                    })\n",
    "                \n",
    "                # Check if there are more comments to fetch\n",
    "                if 'nextPageToken' in response:\n",
    "                    request = self.youtube.commentThreads().list(\n",
    "                        part=\"snippet\",\n",
    "                        videoId=video_id,\n",
    "                        maxResults=max_results,\n",
    "                        pageToken=response['nextPageToken']\n",
    "                    )\n",
    "                else:\n",
    "                    request = None\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "        \n",
    "        # Return the collected comments as a pandas DataFrame\n",
    "        return pd.DataFrame(comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Video IDs from URLs\n",
    "Create utility functions to extract video IDs from different YouTube URL formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0e3GPea1Tyg']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract Video IDs from URLs\n",
    "\n",
    "def extract_video_id(url):\n",
    "    \"\"\"Extract video ID from YouTube URL.\"\"\"\n",
    "    if 'youtu.be' in url:\n",
    "        return url.split('/')[-1].split('?')[0]\n",
    "    elif 'youtube.com' in url:\n",
    "        return url.split('v=')[1].split('&')[0]\n",
    "    return url\n",
    "\n",
    "# Example usage\n",
    "youtube_urls = [\n",
    "    \"https://youtu.be/0e3GPea1Tyg?si=JrfvZL6tlLBfcrVu\"\n",
    "]\n",
    "\n",
    "video_ids = [extract_video_id(url) for url in youtube_urls]\n",
    "video_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect and Process Comments\n",
    "Demonstrate how to collect comments from multiple videos and combine them into a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>likes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Like I said in the video, subscribe if you hav...</td>\n",
       "      <td>@MrBeast</td>\n",
       "      <td>2021-11-24T21:02:45Z</td>\n",
       "      <td>1058903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>imagine finding 061</td>\n",
       "      <td>@Players_1500</td>\n",
       "      <td>2024-12-22T12:12:02Z</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>晚安  希望 韓國女明星(秀智) 和 (潤娥) 可以嫁個好男人 一輩子幸福+458（每天情人...</td>\n",
       "      <td>@許閔翔-i5r</td>\n",
       "      <td>2024-12-22T10:48:47Z</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Beneran😮</td>\n",
       "      <td>@AhmadYusri-v3u</td>\n",
       "      <td>2024-12-22T10:26:03Z</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Who is here after watching Ronald&amp;#39;s video ...</td>\n",
       "      <td>@Hoyadeeduroon</td>\n",
       "      <td>2024-12-22T10:08:46Z</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text           author  \\\n",
       "0  Like I said in the video, subscribe if you hav...         @MrBeast   \n",
       "1                                imagine finding 061    @Players_1500   \n",
       "2  晚安  希望 韓國女明星(秀智) 和 (潤娥) 可以嫁個好男人 一輩子幸福+458（每天情人...         @許閔翔-i5r   \n",
       "3                                           Beneran😮  @AhmadYusri-v3u   \n",
       "4  Who is here after watching Ronald&#39;s video ...   @Hoyadeeduroon   \n",
       "\n",
       "                   date    likes  \n",
       "0  2021-11-24T21:02:45Z  1058903  \n",
       "1  2024-12-22T12:12:02Z        0  \n",
       "2  2024-12-22T10:48:47Z        0  \n",
       "3  2024-12-22T10:26:03Z        0  \n",
       "4  2024-12-22T10:08:46Z        0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collect and Process Comments\n",
    "\n",
    "# Initialize YouTube comment collector\n",
    "collector = YouTubeCommentCollector(api_key)\n",
    "\n",
    "# Collect comments from multiple videos\n",
    "all_comments = []\n",
    "for video_id in video_ids:\n",
    "    comments_df = collector.get_video_comments(video_id)\n",
    "    all_comments.append(comments_df)\n",
    "\n",
    "# Combine all comments into a single pandas DataFrame\n",
    "combined_df = pd.concat(all_comments, ignore_index=True)\n",
    "\n",
    "# Display the combined DataFrame\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store Comments Data\n",
    "Save the collected comments to a CSV file and show basic statistics about the collected data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of comments collected: 151297\n",
      "Number of unique authors: 130816\n",
      "Most liked comment:\n",
      "text      Like I said in the video, subscribe if you hav...\n",
      "author                                             @MrBeast\n",
      "date                                   2021-11-24T21:02:45Z\n",
      "likes                                               1058903\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Store Comments Data\n",
    "\n",
    "# Save the collected comments to a CSV file\n",
    "output_file = '../data/youtube_comments.csv'\n",
    "combined_df.to_csv(output_file, index=False)\n",
    "\n",
    "# Show basic statistics about the collected data\n",
    "print(\"Number of comments collected:\", len(combined_df))\n",
    "print(\"Number of unique authors:\", combined_df['author'].nunique())\n",
    "print(\"Most liked comment:\")\n",
    "print(combined_df.loc[combined_df['likes'].idxmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
