{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup YouTube API Client\n",
    "Import required libraries and initialize the YouTube API client with authentication credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from googleapiclient.discovery import build\n",
    "from google.oauth2.credentials import Credentials\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Initialize the YouTube API client with authentication credentials\n",
    "api_key = 'AIzaSyA8W-97TUc2_0R-IAq3mJU2G0hEAekPcyc'\n",
    "youtube = build('youtube', 'v3', developerKey=api_key, static_discovery=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Comment Collection Functions\n",
    "Implement the YouTubeCommentCollector class with methods to fetch comments from videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YouTubeCommentCollector:\n",
    "    def __init__(self, api_key):\n",
    "        # Initialize the YouTube API client\n",
    "        self.youtube = build('youtube', 'v3', developerKey=api_key, static_discovery=False)\n",
    "\n",
    "    def get_video_comments(self, video_id, max_results=100):\n",
    "        comments = []\n",
    "        try:\n",
    "            # Create a request to fetch comments\n",
    "            request = self.youtube.commentThreads().list(\n",
    "                part=\"snippet\",\n",
    "                videoId=video_id,\n",
    "                maxResults=max_results\n",
    "            )\n",
    "            \n",
    "            while request:\n",
    "                # Execute the request and get the response\n",
    "                response = request.execute()\n",
    "                \n",
    "                # Extract comments from the response\n",
    "                for item in response['items']:\n",
    "                    comment = item['snippet']['topLevelComment']['snippet']\n",
    "                    comments.append({\n",
    "                        'text': comment['textDisplay'],\n",
    "                        'author': comment['authorDisplayName'],\n",
    "                        'date': comment['publishedAt'],\n",
    "                        'likes': comment['likeCount'],\n",
    "                    })\n",
    "                \n",
    "                # Check if there are more comments to fetch\n",
    "                if 'nextPageToken' in response:\n",
    "                    request = self.youtube.commentThreads().list(\n",
    "                        part=\"snippet\",\n",
    "                        videoId=video_id,\n",
    "                        maxResults=max_results,\n",
    "                        pageToken=response['nextPageToken']\n",
    "                    )\n",
    "                else:\n",
    "                    request = None\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "        \n",
    "        # Return the collected comments as a pandas DataFrame\n",
    "        return pd.DataFrame(comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Video IDs from URLs\n",
    "Create utility functions to extract video IDs from different YouTube URL formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Video IDs from URLs\n",
    "\n",
    "def extract_video_id(url):\n",
    "    \"\"\"Extract video ID from YouTube URL.\"\"\"\n",
    "    if 'youtu.be' in url:\n",
    "        return url.split('/')[-1].split('?')[0]\n",
    "    elif 'youtube.com' in url:\n",
    "        return url.split('v=')[1].split('&')[0]\n",
    "    return url\n",
    "\n",
    "# Example usage\n",
    "youtube_urls = [\n",
    "    \"https://youtu.be/ovtz7__1UrI?si=mnNJvQvYS0yu-i6q\",\n",
    "    \"https://www.youtube.com/watch?v=ovtz7__1UrI\"\n",
    "]\n",
    "\n",
    "video_ids = [extract_video_id(url) for url in youtube_urls]\n",
    "video_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect and Process Comments\n",
    "Demonstrate how to collect comments from multiple videos and combine them into a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect and Process Comments\n",
    "\n",
    "# Initialize YouTube comment collector\n",
    "collector = YouTubeCommentCollector(api_key)\n",
    "\n",
    "# Collect comments from multiple videos\n",
    "all_comments = []\n",
    "for video_id in video_ids:\n",
    "    comments_df = collector.get_video_comments(video_id)\n",
    "    all_comments.append(comments_df)\n",
    "\n",
    "# Combine all comments into a single pandas DataFrame\n",
    "combined_df = pd.concat(all_comments, ignore_index=True)\n",
    "\n",
    "# Display the combined DataFrame\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store Comments Data\n",
    "Save the collected comments to a CSV file and show basic statistics about the collected data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store Comments Data\n",
    "\n",
    "# Save the collected comments to a CSV file\n",
    "output_file = 'youtube_comments.csv'\n",
    "combined_df.to_csv(output_file, index=False)\n",
    "\n",
    "# Show basic statistics about the collected data\n",
    "print(\"Number of comments collected:\", len(combined_df))\n",
    "print(\"Number of unique authors:\", combined_df['author'].nunique())\n",
    "print(\"Most liked comment:\")\n",
    "print(combined_df.loc[combined_df['likes'].idxmax()])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
